{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Classification_TF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6FfK-FIJRRC",
        "colab_type": "text"
      },
      "source": [
        "Install Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SB_2-8QJTue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "700c88c5-3e81-42e3-932a-767b6a2d4e2a"
      },
      "source": [
        "!pip install -U tensorflow==2.0.0 --quiet"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 86.3MB 45kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 46.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkZV0iu1MQK_",
        "colab_type": "text"
      },
      "source": [
        "Import Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yy450yDMSck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow  as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zGQq1iAMUnb",
        "colab_type": "text"
      },
      "source": [
        "Import MNIST from Tensorflow and create Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2alxeLzEMa9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2e732164-3287-4ba1-d4c6-553e4519d72e"
      },
      "source": [
        "(trainX,trainY),(testX,testY) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR_Ut02gMudE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35dc4ad2-0499-421b-ea7e-7261e3d7456a"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZRBtIaSMz5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3aa49c2-2f42-4f4d-dd16-831a7bd73cc6"
      },
      "source": [
        "trainY.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPYINf7bM4qI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9def929e-43ed-4bc3-84ff-397b5ebc3657"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWhh2bCfM6nW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e847124a-c709-497e-d419-b3f54defaa3c"
      },
      "source": [
        "testY.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MvuXQuLM7lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "640415f3-18bc-41ce-b007-742e8ba6b748"
      },
      "source": [
        "#Print first number in train set\n",
        "trainX[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52UlUu_cVs2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ba9a2607-4d85-4b9d-d550-ef5937e39a9e"
      },
      "source": [
        "#Print first Image\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(trainX[0],cmap='gray')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f58c9e2f0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyFUsgdWV38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ6swyV1Wz0_",
        "colab_type": "text"
      },
      "source": [
        "Convert lables into multiple values (One Hot Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv5O4fb1Xr0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Before conversion of labels\n",
        "print(trainY.shape)\n",
        "print(\"First two examples are : \",trainY[0:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT6PTYWYXA7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#One Hot Encoding\n",
        "trainY= tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY= tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhuiv1yIXg6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#After conversion of labels\n",
        "print(trainY.shape)\n",
        "print(\"First two examples are : \",trainY[0:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOB5qOhRYFt2",
        "colab_type": "text"
      },
      "source": [
        "Building the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQXhZKDYYJC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize sequential model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3Xn8qdqYeIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshape data from matrix(2D) to Vector (1D) -24x24 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,) ,input_shape=(28,28,)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhdiVsJjZWLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalize the data - Batch normalization does ZScore Normalization\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGNYZMHVZgqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add Dense functions to give 10 equations\n",
        "model.add(tf.keras.layers.Dense(10, activation ='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G_dvqMcZ79g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics =['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI-i8JIWiZXG",
        "colab_type": "text"
      },
      "source": [
        "Execute the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6q3ATY2ia7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ecc960ee-1e0f-4bc8-c073-8be86ed8e25a"
      },
      "source": [
        "model.fit(trainX,trainY,validation_data=(testX,testY),epochs=100, batch_size=trainX.shape[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 3.0935 - accuracy: 0.1143 - val_loss: 20.6074 - val_accuracy: 0.1183\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 2.9972 - accuracy: 0.1253 - val_loss: 14.1012 - val_accuracy: 0.1314\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.9044 - accuracy: 0.1369 - val_loss: 11.0790 - val_accuracy: 0.1456\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 2.8150 - accuracy: 0.1493 - val_loss: 9.2247 - val_accuracy: 0.1578\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 2.7291 - accuracy: 0.1619 - val_loss: 7.9359 - val_accuracy: 0.1705\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.6466 - accuracy: 0.1758 - val_loss: 6.9743 - val_accuracy: 0.1869\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.5674 - accuracy: 0.1904 - val_loss: 6.2230 - val_accuracy: 0.2012\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 2.4916 - accuracy: 0.2045 - val_loss: 5.6169 - val_accuracy: 0.2139\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.4190 - accuracy: 0.2192 - val_loss: 5.1162 - val_accuracy: 0.2274\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.3496 - accuracy: 0.2349 - val_loss: 4.6949 - val_accuracy: 0.2392\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.2834 - accuracy: 0.2516 - val_loss: 4.3352 - val_accuracy: 0.2529\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.2203 - accuracy: 0.2695 - val_loss: 4.0245 - val_accuracy: 0.2639\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.1601 - accuracy: 0.2873 - val_loss: 3.7535 - val_accuracy: 0.2757\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 2.1029 - accuracy: 0.3063 - val_loss: 3.5150 - val_accuracy: 0.2870\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.0484 - accuracy: 0.3250 - val_loss: 3.3037 - val_accuracy: 0.2990\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.9966 - accuracy: 0.3442 - val_loss: 3.1153 - val_accuracy: 0.3096\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.9474 - accuracy: 0.3642 - val_loss: 2.9464 - val_accuracy: 0.3219\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.9006 - accuracy: 0.3848 - val_loss: 2.7942 - val_accuracy: 0.3350\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.8561 - accuracy: 0.4062 - val_loss: 2.6565 - val_accuracy: 0.3488\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.8138 - accuracy: 0.4259 - val_loss: 2.5315 - val_accuracy: 0.3608\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.7735 - accuracy: 0.4448 - val_loss: 2.4176 - val_accuracy: 0.3736\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.7353 - accuracy: 0.4618 - val_loss: 2.3134 - val_accuracy: 0.3872\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.6989 - accuracy: 0.4780 - val_loss: 2.2180 - val_accuracy: 0.4003\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.6642 - accuracy: 0.4926 - val_loss: 2.1303 - val_accuracy: 0.4146\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 1.6313 - accuracy: 0.5058 - val_loss: 2.0495 - val_accuracy: 0.4267\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5999 - accuracy: 0.5182 - val_loss: 1.9750 - val_accuracy: 0.4401\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5699 - accuracy: 0.5290 - val_loss: 1.9061 - val_accuracy: 0.4544\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5414 - accuracy: 0.5384 - val_loss: 1.8423 - val_accuracy: 0.4682\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5142 - accuracy: 0.5484 - val_loss: 1.7830 - val_accuracy: 0.4819\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.4882 - accuracy: 0.5578 - val_loss: 1.7280 - val_accuracy: 0.4947\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.4633 - accuracy: 0.5660 - val_loss: 1.6768 - val_accuracy: 0.5062\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 1.4396 - accuracy: 0.5735 - val_loss: 1.6290 - val_accuracy: 0.5182\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.4169 - accuracy: 0.5810 - val_loss: 1.5844 - val_accuracy: 0.5305\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3951 - accuracy: 0.5885 - val_loss: 1.5427 - val_accuracy: 0.5418\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3743 - accuracy: 0.5955 - val_loss: 1.5037 - val_accuracy: 0.5542\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 1.3543 - accuracy: 0.6019 - val_loss: 1.4671 - val_accuracy: 0.5647\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3351 - accuracy: 0.6082 - val_loss: 1.4327 - val_accuracy: 0.5746\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3166 - accuracy: 0.6139 - val_loss: 1.4003 - val_accuracy: 0.5830\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2989 - accuracy: 0.6195 - val_loss: 1.3698 - val_accuracy: 0.5909\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2819 - accuracy: 0.6252 - val_loss: 1.3411 - val_accuracy: 0.5993\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2655 - accuracy: 0.6302 - val_loss: 1.3140 - val_accuracy: 0.6060\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2497 - accuracy: 0.6353 - val_loss: 1.2883 - val_accuracy: 0.6121\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2344 - accuracy: 0.6401 - val_loss: 1.2641 - val_accuracy: 0.6187\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2197 - accuracy: 0.6452 - val_loss: 1.2410 - val_accuracy: 0.6265\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2055 - accuracy: 0.6494 - val_loss: 1.2192 - val_accuracy: 0.6329\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1918 - accuracy: 0.6533 - val_loss: 1.1985 - val_accuracy: 0.6391\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1785 - accuracy: 0.6576 - val_loss: 1.1787 - val_accuracy: 0.6459\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1657 - accuracy: 0.6617 - val_loss: 1.1599 - val_accuracy: 0.6515\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 1.1533 - accuracy: 0.6658 - val_loss: 1.1420 - val_accuracy: 0.6568\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1412 - accuracy: 0.6693 - val_loss: 1.1249 - val_accuracy: 0.6620\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1296 - accuracy: 0.6730 - val_loss: 1.1086 - val_accuracy: 0.6669\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1183 - accuracy: 0.6768 - val_loss: 1.0930 - val_accuracy: 0.6718\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1073 - accuracy: 0.6801 - val_loss: 1.0781 - val_accuracy: 0.6760\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0967 - accuracy: 0.6830 - val_loss: 1.0638 - val_accuracy: 0.6804\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0864 - accuracy: 0.6859 - val_loss: 1.0500 - val_accuracy: 0.6843\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0763 - accuracy: 0.6888 - val_loss: 1.0369 - val_accuracy: 0.6881\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0666 - accuracy: 0.6920 - val_loss: 1.0242 - val_accuracy: 0.6925\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0571 - accuracy: 0.6950 - val_loss: 1.0121 - val_accuracy: 0.6971\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0478 - accuracy: 0.6978 - val_loss: 1.0004 - val_accuracy: 0.7006\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0389 - accuracy: 0.7007 - val_loss: 0.9891 - val_accuracy: 0.7042\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0301 - accuracy: 0.7035 - val_loss: 0.9782 - val_accuracy: 0.7074\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0216 - accuracy: 0.7061 - val_loss: 0.9678 - val_accuracy: 0.7111\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0133 - accuracy: 0.7087 - val_loss: 0.9577 - val_accuracy: 0.7146\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0052 - accuracy: 0.7113 - val_loss: 0.9479 - val_accuracy: 0.7178\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9973 - accuracy: 0.7138 - val_loss: 0.9385 - val_accuracy: 0.7204\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9896 - accuracy: 0.7160 - val_loss: 0.9294 - val_accuracy: 0.7232\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9821 - accuracy: 0.7185 - val_loss: 0.9206 - val_accuracy: 0.7258\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9748 - accuracy: 0.7210 - val_loss: 0.9120 - val_accuracy: 0.7282\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9676 - accuracy: 0.7233 - val_loss: 0.9038 - val_accuracy: 0.7306\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9606 - accuracy: 0.7253 - val_loss: 0.8958 - val_accuracy: 0.7332\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9538 - accuracy: 0.7275 - val_loss: 0.8880 - val_accuracy: 0.7351\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9471 - accuracy: 0.7296 - val_loss: 0.8805 - val_accuracy: 0.7374\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9406 - accuracy: 0.7317 - val_loss: 0.8731 - val_accuracy: 0.7398\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9342 - accuracy: 0.7334 - val_loss: 0.8660 - val_accuracy: 0.7421\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9279 - accuracy: 0.7355 - val_loss: 0.8591 - val_accuracy: 0.7437\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9218 - accuracy: 0.7377 - val_loss: 0.8524 - val_accuracy: 0.7460\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9158 - accuracy: 0.7397 - val_loss: 0.8459 - val_accuracy: 0.7479\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9100 - accuracy: 0.7415 - val_loss: 0.8396 - val_accuracy: 0.7496\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9042 - accuracy: 0.7434 - val_loss: 0.8334 - val_accuracy: 0.7513\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.8986 - accuracy: 0.7455 - val_loss: 0.8274 - val_accuracy: 0.7535\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8931 - accuracy: 0.7472 - val_loss: 0.8215 - val_accuracy: 0.7554\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8877 - accuracy: 0.7488 - val_loss: 0.8158 - val_accuracy: 0.7574\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8825 - accuracy: 0.7504 - val_loss: 0.8103 - val_accuracy: 0.7591\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8773 - accuracy: 0.7522 - val_loss: 0.8049 - val_accuracy: 0.7609\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8722 - accuracy: 0.7536 - val_loss: 0.7996 - val_accuracy: 0.7620\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8672 - accuracy: 0.7552 - val_loss: 0.7944 - val_accuracy: 0.7636\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8623 - accuracy: 0.7568 - val_loss: 0.7894 - val_accuracy: 0.7652\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8575 - accuracy: 0.7583 - val_loss: 0.7845 - val_accuracy: 0.7668\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8528 - accuracy: 0.7599 - val_loss: 0.7797 - val_accuracy: 0.7690\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8482 - accuracy: 0.7613 - val_loss: 0.7750 - val_accuracy: 0.7705\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8437 - accuracy: 0.7627 - val_loss: 0.7704 - val_accuracy: 0.7721\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8392 - accuracy: 0.7642 - val_loss: 0.7660 - val_accuracy: 0.7738\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8349 - accuracy: 0.7656 - val_loss: 0.7616 - val_accuracy: 0.7750\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.8306 - accuracy: 0.7669 - val_loss: 0.7573 - val_accuracy: 0.7764\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8264 - accuracy: 0.7682 - val_loss: 0.7532 - val_accuracy: 0.7779\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8222 - accuracy: 0.7697 - val_loss: 0.7491 - val_accuracy: 0.7789\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.8181 - accuracy: 0.7710 - val_loss: 0.7451 - val_accuracy: 0.7800\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8141 - accuracy: 0.7724 - val_loss: 0.7411 - val_accuracy: 0.7807\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8102 - accuracy: 0.7736 - val_loss: 0.7373 - val_accuracy: 0.7817\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8063 - accuracy: 0.7748 - val_loss: 0.7336 - val_accuracy: 0.7824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f58c4904080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLqNp57ojhoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}